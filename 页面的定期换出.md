# Memory-Management

为了避免总是在CPU忙碌的时候，也就是在缺页异常发生的时候，临时在来搜寻可供换出的内存页面加以换出，linux内核定期地检查并且预先将若干页面换出，腾出空间，以减轻系统在缺页异常发生时的负担。当然，由于无法确切地预测页面的使用，及时这样做了也还是不能完全杜绝在缺页异常发生时内存没有空闲页面，而只好临时寻找可换成页面的可能。但是，这样毕竟可以减少发生概率。并且，通过选择适当的参数，例如每隔多久换出一次，每次换出多少页面，可以使得缺页异常发生时必须临时寻找页面换出的情况实际上很少发生。为此，在linux内核中设置了一个专司定期将页面换出的“守护神”kswapd。

从原理上说，kswapd相当于一个进程，有其自身的进程控制块task_struct结构，跟其它进程一样搜内核调度。而正因为内核将它按进程来调度，就可以让他在系统相对空闲的时候来运行。不过，与普通的进程相比，kswapd还是有其特殊性。首先，它没有自己独立的地址空间，所以在近代操作系统理论中称为“线程”以示区别。那么，kswapd使用谁的地址空间呢？它使用的是内核的空间。在这一点上，它与中断服务程序相似。其次，它的代码是静态地连接在内核中的，可以直接使用内核中的各种子程序，而不像普通的进程那样只能通过系统调用，使用预先定义的一组功能。

本节讲诉kswapd受内核调度而运行并走完一条例行路线的全过程。

线程kswapd的源代码基本上都在mm/vmscan.c中。先来看它的建立：

```c++
static int __init kswapd_init(void)
{
     printk("Starting kswapd v1.8\n");
     swap_setup();
     kernel_thread(kswapd, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGNAL);
     kernel_thread(kreclaimd, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGNAL);
     return 0;
}
```
函数kswapd_init()是在系统初始化期间受到调用的，它主要做两件事。第一件是在swap_setup()中根据物理内存的大小设定一个全局量page_cluster：

```c++
[kswapd_init()>swap_setup()]
 /*
  * Perform any setup for the swap system
  */
void __init swap_setup(void)
{
     /* Use a smaller cluster for memory <16MB or <32MB */
     if (num_physpages < ((16 * 1024 * 1024) >> PAGE_SHIFT))
          page_cluster = 2;
     else if (num_physpages < ((32 * 1024 * 1024) >> PAGE_SHIFT))
          page_cluster = 3;
     else
          page_cluster = 4;
}
```

这是一个跟磁盘设备驱动有关的参数。由于读磁盘时先要经过寻到，并且寻道是个比较费时间的操作，所以如果每次只读一个页面是不经济的。比较好的办法是既然读了干脆多读几个页面，称为“预读”。但是预读意味着每次需要暂存更多的内存页面，所以需要决定一个适当的数量，而根据物理内存本身的大小来确定这个参数显然是合理的。第二件事就是创建线程kswapd，这是由kernel_thread()来完成。这里还创建了另一个线程kreclaimd，也是跟存储管理有关，不过不像kswapd那么复杂和重要。这里暂且假定kswapd就此建立了，并且从函数kswapd()开始执行。其代码在mm/vmscan.c中：

```c++
/*
 * The background pageout daemon, started as a kernel thread
 * from the init process.
 *
 * This basically trickles out pages so that we have _some_
 * free memory available even if there is no other activity
 * that frees anything up. This is needed for things like routing
 * etc, where we otherwise might have all activity going on in
 * asynchronous contexts that cannot page things out.
 *
 * If there are applications that are active memory-allocators
 * (most normal use), this basically shouldn't matter.
 */
int kswapd(void *unused)
{
    struct task_struct *tsk = current;

    tsk->session = 1;
    tsk->pgrp = 1;
    strcpy(tsk->comm, "kswapd");
    sigfillset(&tsk->blocked);
    kswapd_task = tsk;

    /*
     * Tell the memory management that we're a "memory allocator",
     * and that if we need more memory we should get access to it
     * regardless (see "__alloc_pages()"). "kswapd" should
     * never get caught in the normal page freeing logic.
     *
     * (Kswapd normally doesn't need memory anyway, but sometimes
     * you need a small amount of memory in order to be able to
     * page out something else, and this flag essentially protects
     * us from recursively trying to free more memory as we're
     * trying to free the first piece of memory in the first place).
     */
    tsk->flags |= PF_MEMALLOC;

    /*
     * Kswapd main loop.
     */
    for (;;) {
      static int recalc = 0;

      /* If needed, try to free some memory. */
      if (inactive_shortage() || free_shortage()) {
          int wait = 0;
      /* Do we need to do some synchronous flushing? */ 
      if (waitqueue_active(&kswapd_done))
          wait = 1;
      do_try_to_free_pages(GFP_KSWAPD, wait);
      }

      /*
       * Do some (very minimal) background scanning. This
       * will scan all pages on the active list once
       * every minute. This clears old referenced bits
       * and moves unused pages to the inactive list.
       */
       refill_inactive_scan(6, 0);

      /* Once a second, recalculate some VM stats. */
      if (time_after(jiffies, recalc + HZ)) {
          recalc = jiffies;
          recalculate_vm_stats();
     }

     /*
      * Wake up everybody waiting for free memory
      * and unplug the disk queue.
      */
     wake_up_all(&kswapd_done);
     run_task_queue(&tq_disk);

     /*
      * We go to sleep if either the free page shortage
      * or the inactive page shortage is gone. We do this
      * because:
      * 1) we need no more free pages   or
      * 2) the inactive pages need to be flushed to disk,
      *    it wouldn't help to eat CPU time now ...
      *
      * We go to sleep for one second, but if it's needed
      * we'll be woken up earlier...
      */
     if (!free_shortage() || !inactive_shortage()) {
           interruptible_sleep_on_timeout(&kswapd_wait, HZ);
     /*
      * If we couldn't free enough memory, we see if it was
      * due to the system just not having enough memory.
      * If that is the case, the only solution is to kill
      * a process (the alternative is enternal deadlock).
      *
      * If there still is enough memory around, we just loop
      * and try free some more memory...
      */
      } else if (out_of_memory()) {
        oom_kill();
      }
   }
}
```
在一些简单的初始化操作以后，程序便进入一个无限循环。在每次循环的末尾一般都会调用interruptible_sleep_on_timeout()进入睡眠，让内核自由地调度别的进程运行。但是内核在一定时间以后又会唤醒并调度kswapd继续运行，这时候kswapd就又回到这无限循环开始的位置。那么，这“一定时间”是多长呢，这就是常数HZ。HZ决定
了内核中每秒有多少次时钟中断。用户可以在编译内核前的系统配置阶段改变其数值，但是一经编译就确定下来了。所以，在调用interruptiable_sleep_on_timeout()时的参数为HZ，表示1秒中以后又要调度kswapd继续运行。换言之，对interruptible_sleep_on_timeout()的调度一进去就得1秒钟以后才回来。但是，在有些情况下内核也会在不到1秒钟时就把它唤醒，那样kswapd就会提前返回并开始新的一轮循环。所以，这个循环至少每隔1秒钟执行一遍，这就是kswapd的例行路线。

那么，kswapd在至少每秒一次的例行路线中做些什么呢？可以把它分成两部分。第一部分是在发现物理页面已经短缺的情况下才进行的，目的在于裕兴找出若干页面，且将这些页面的樱色断开，使这些物理页面从活跃状态转入不活跃状态，为页面的换出做好准备。第二部分是每次都要执行的，目的正在于把已经处于不活跃状态的“脏”页写入交换设备，使他们成为不活跃“干净”页面继续缓存，或进一步回收一些这样的页面成为空闲页面。

先看第一部分，首先检查内存中可供分配或周转的物理页面是否短缺：

```c++
[kswapd()>inactive_shortage()]
 /*
  * How many inactive pages are we short?
  */
int inactive_shortage(void)
{
    int shortage = 0;

    shortage += freepages.high;
    shortage += inactive_target;
    shortage -= nr_free_pages();
    shortage -= nr_inactive_clean_pages();
    shortage -= nr_inactive_dirty_pages;

    if (shortage > 0)
       return shortage;
    return 0;
}
```

系统中应该维持的物理页面供应量有两个全局量确定，那就是freepages.high和inactive_target,分别为空闲页面的数量和不活跃页面的数量，两者之和为正常情况下潜在的供应量。而这些内存页面来源有三个方面。一方面是当前尚存的空闲页面，这是立即就可以分配的页面。这些页面分散在各个页面管理区中，并且合并成地址连续，大小为2,4,8...个页面的页面块，其数量由nr_free_pages()加以统计。另一方面是现有不活跃“干净”页面，这些页面本质上是马上可以分配的页面，但是页面中的内容
可能还会用到，所以多保留一些这样的页面有助于减少从交换设备的读入。这些页面也分散在各个页面管理区，但是不合并成块，其数量由nr_inactive_clean_pages()加以统计。最后是现有的不活跃“脏”页面，这些页面要先加以“净化”，即写入交换设备后才能投入分配。这种页面全部在同一队列中，内核中的全局量nr_inactive_dirty_pages记录着当前此类页面的数量。上述两个函数的代码都在mm/page_alloc.c中。

不过，光维持潜在的物理页面供应总量还不够，还是通过free_shortage()检查是否有某个具体管理区中有严重的短缺，即直接可供分配的页面数量（除不活跃“脏”页面以外）是否小于一个最低限度，这个函数的代码在mm/vmscan.c中。

如果发现可供分配的内存页面短缺，那就要设法释放和换出若干页面，这是通过do_try_to_free_pages()完成的。不过在此之前还有调用waitqueue_active(),看看kswapd_done队列中是否有函数在等待执行，并把查看结果作为参数传递给do_try_to_free_pages()。在内核中有几个特殊的队列，内核中各个部分（主要是设备驱动）可以把一些底层函数挂入这样的队列，是的这些函数在某种时间发生时就能的到执行。而kswapd_done，就正是这样的一个队列。凡是挂入这个队列的函数，在kswapd每完成一趟例行的操作时就能得到执行。

```c++
[kswapd()>waitqueue_active()]
static inline int waitqueue_active(wait_queue_head_t *q)
{
    #if WAITQUEUE_DEBUG
    if (!q)
       WQ_BUG();
    CHECK_MAGIC_WQHEAD(q);
    #endif
    return !list_empty(&q->task_list);
}
```

下面就是调用do_try_to_free_pages(),试图腾出一些内存页面。

```c++
[kswapd()>do_try_to_free_pages()]
static int do_try_to_free_pages(unsigned int gfp_mask, int user)
{
    int ret = 0;

    /*
     * If we're low on free pages, move pages from the
     * inactive_dirty list to the inactive_clean list.
     *
     * Usually bdflush will have pre-cleaned the pages
     * before we get around to moving them to the other
     * list, so this is a relatively cheap operation.
     */
    if (free_shortage() || nr_inactive_dirty_pages > nr_free_pages() +  nr_inactive_clean_pages())
        ret += page_launder(gfp_mask, user);
    /*
     * If needed, we move pages from the active list
     * to the inactive list. We also "eat" pages from
     * the inode and dentry cache whenever we do this.
     */
    if (free_shortage() || inactive_shortage()) {
        shrink_dcache_memory(6, gfp_mask);
        shrink_icache_memory(6, gfp_mask);
        ret += refill_inactive(gfp_mask, user);
    } else {
      /*
       * Reclaim unused slab cache memory.
       */
       kmem_cache_reap(gfp_mask);
       ret = 1;
    }

    return ret;
}
```

将活跃页面的映射断开，使之转入不活跃状态，甚至进而换出到交换设备上，使不得已而为之，因为谁也不能精确地预测到底哪一些页面是适合的换出对象。虽然一般而言“最近最少用的”是个有效的标准，但也不是“放诸四海而皆准”。所以，能够不动“现役”页面是最理想的。基于这样的考虑，这是所做的是先易后难，逐步加强力度。首先是调用page_launder(),试图把已经转入不活跃状态的“脏”页面“洗净”，使他们变成立即可以分配的页面。这个函数一方面（基本上）定期地受到kswapd()调用，一方面在每当需要分配内存页面，而又无页面可供分配时，临时地受到调用。

```c++
#define MAX_LAUNDER (4 * (1 << page_cluster))
int page_launder(int gfp_mask, int sync)
{
    int launder_loop, maxscan, cleaned_pages, maxlaunder;
    int can_get_io_locks;
    struct list_head * page_lru;
    struct page * page;

    /*
     * We can only grab the IO locks (eg. for flushing dirty
     * buffers to disk) if __GFP_IO is set.
     */
    can_get_io_locks = gfp_mask & __GFP_IO;

    launder_loop = 0;
    maxlaunder = 0;
    cleaned_pages = 0;

    dirty_page_rescan:
    spin_lock(&pagemap_lru_lock);
    maxscan = nr_inactive_dirty_pages;
    while ((page_lru = inactive_dirty_list.prev) != &inactive_dirty_list && maxscan-- > 0) {
          page = list_entry(page_lru, struct page, lru);

    /* Wrong page on list?! (list corruption, should not happen) */
    if (!PageInactiveDirty(page)) {
         printk("VM: page_launder, wrong page on list.\n");
         list_del(page_lru);
         nr_inactive_dirty_pages--;
         page->zone->inactive_dirty_pages--;
         continue;
    }

    /* Page is or was in use?  Move it to the active list. */
    if (PageTestandClearReferenced(page) || page->age > 0 ||  (!page->buffers && page_count(page) > 1) ||
    page_ramdisk(page)) {
        del_page_from_inactive_dirty_list(page);
        add_page_to_active_list(page);
        continue;
    }

    /*
     * The page is locked. IO in progress?
     * Move it to the back of the list.
     */
    if (TryLockPage(page)) { 
       list_del(page_lru);
       list_add(page_lru, &inactive_dirty_list);
       continue;
    }

    /*
     * Dirty swap-cache page? Write it out if
     * last copy..
     */
    if (PageDirty(page)) {
        int (*writepage)(struct page *) = page->mapping->a_ops->writepage;
        int result;

        if (!writepage)
            goto page_active;

        /* First time through? Move it to the back of the list */
        if (!launder_loop) {
                list_del(page_lru);
                list_add(page_lru, &inactive_dirty_list);
                UnlockPage(page);
                continue;
        }

        /* OK, do a physical asynchronous write to swap.  */
        ClearPageDirty(page);
        page_cache_get(page);
        spin_unlock(&pagemap_lru_lock);

        result = writepage(page);
        page_cache_release(page);

        /* And re-start the thing.. */
        spin_lock(&pagemap_lru_lock);
        if (result != 1)
            continue;
        /* writepage refused to do anything */
        set_page_dirty(page);
        goto page_active;
   }

    /*
     * If the page has buffers, try to free the buffer mappings
     * associated with this page. If we succeed we either free
     * the page (in case it was a buffercache only page) or we
     * move the page to the inactive_clean list.
     *
     * On the first round, we should free all previously cleaned
     * buffer pages
     */
    if (page->buffers) { 
          int wait, clearedbuf;
          int freed_page = 0;
    /*
     * Since we might be doing disk IO, we have to
     * drop the spinlock and take an extra reference
     * on the page so it doesn't go away from under us.
     */
          del_page_from_inactive_dirty_list(page);
          page_cache_get(page);
          spin_unlock(&pagemap_lru_lock);

      /* Will we do (asynchronous) IO? */
      if (launder_loop && maxlaunder == 0 && sync)
             wait = 2; /* Synchrounous IO */
      else if (launder_loop && maxlaunder-- > 0)
             wait = 1; /* Async IO */
      else
             wait = 0; /* No IO */

      /* Try to free the page buffers. */
      clearedbuf = try_to_free_buffers(page, wait);

    /*
     * Re-take the spinlock. Note that we cannot
     * unlock the page yet since we're still
     * accessing the page_struct here...
     */
     spin_lock(&pagemap_lru_lock);

     /* The buffers were not freed. */
     if (!clearedbuf) {
        add_page_to_inactive_dirty_list(page);

     /* The page was only in the buffer cache. */
    } else if (!page->mapping) {
          atomic_dec(&buffermem_pages);
          freed_page = 1;
          cleaned_pages++;

     /* The page has more users besides the cache and us. */
    } else if (page_count(page) > 2) {
          add_page_to_active_list(page);

     /* OK, we "created" a freeable page. */
   } else /* page->mapping && page_count(page) == 2 */ { 
          add_page_to_inactive_clean_list(page);
          cleaned_pages++;
   }

    /*
     * Unlock the page and drop the extra reference.
     * We can only do it here because we ar accessing
     * the page struct above.
     */
    UnlockPage(page);
    page_cache_release(page);

    /*
     * If we're freeing buffer cache pages, stop when
     * we've got enough free memory.
     */
    if (freed_page && !free_shortage())
       break;
       continue;
    } else if (page->mapping && !PageDirty(page)) {
    /*
     * If a page had an extra reference in
     * deactivate_page(), we will find it here.
     * Now the page is really freeable, so we
     * move it to the inactive_clean list.
     */
      del_page_from_inactive_dirty_list(page);
      add_page_to_inactive_clean_list(page);
      UnlockPage(page);
      cleaned_pages++;
    } else {
page_active:
    /*
     * OK, we don't know what to do with the page.
     * It's no use keeping it here, so we move it to
     * the active list.
     */
     del_page_from_inactive_dirty_list(page);
     add_page_to_active_list(page);
     UnlockPage(page);
   }
   }
spin_unlock(&pagemap_lru_lock);
```

代码中局部量cleaned_pages用来累计被“洗清”的页面数量。另一个局部量launder_loop用来控制扫描不活跃“脏”页面队列的次数。在第一趟扫描时launcher_loop为0，如果有必要进行第二趟扫描，则将其设成1并转回标号dirty_page_rescan处，开始又一次扫描。

对不活跃“脏”页面队列的扫描时通过一个while循环进行的。由于在循环中会把有些页面从当前位置移到队列的尾部，所以除沿着链接指针扫描还要对数量加以控制，才能避免重复处理同一页面，甚至陷入死循环，这就是变量maxscan的作用。

对于队列中的每一个页面，首先要检查它的PG_inactive_dirty标记位为1，否则就根本不应该出现在这个队列中；着一定是出了什么毛病，所以把它从队列中删除。除此之外，对于正常的不活跃“脏”页面，则要依次做下述的检查并做相应的处理。

（1）有些页面虽然已经进入不活跃“脏”页面队列，但是由于情况已经变化，或者当初进入这个队列本来就是“冤家错案”，因而需要回到活跃页面队列中。这样的页面有：页面在进入不活跃“脏”页面队列之后又受到了访问，即发生了以此页面为目标的缺页异常，从而恢复了该页面的映射。页面的“寿命”还未耗尽。页面的page结构中有个字段age,其数值与页面受访问的频繁程度有关。页面并不用作读/写文件的缓冲，而页面的使用计数却又大约1。说明页面在失少一个进程的映射表中有映射。如前所述，一个页面的使用计数在分配时设成1，以后对该页面的每一次使这个计数加1，包括将页面用作读/写文件的缓冲。如果一个页面没有用作读/写文件的缓冲，那么只要计数大于1就必定还有进程在使用这个页面。页面在受到进程用户空间映射的同时又用于ramdisk，即用内存空间来模拟磁盘，这种页面当然不应该换出到磁盘上。

（2）页面已被锁住，所以TryLockPage()返回1，这表明正在对此页面进行操作，如输入/输出，这样的页面应该留在不活跃“脏”页面队列中，但是把它移到队列的尾部。注意，对于未被锁住的页面，现在已经锁上了。

（3）如果页面仍是“脏”的，即page结构的PG_dirty标记位为1，则原则上将其写出到交换设备上，但还有些特殊情况要考虑。首先，所属的address_space数据结构必须提供页面写出操作的函数，否则就只好转到page_active处，将页面送回活跃页面队列中。对于一般的页面交换，所属的address_space数据结构为swapper_space,其address_space_operations结构为swap_aops,所提供的页面写出操作为swap_writepage(),过这一“关”是没有问题的。在这一趟扫描中，只是把页面移到同一队列的尾部，而并不写出页面。如果进行第二趟扫描的话，那就真的要把页面写出去了。写之前先通过先通过ClearPageDirty()把页面的PG_dirty标记位清成0，然后通过由所属address_space数据结构所提供的函数把页面写出去。根据页面的不同使用目的，例如普通的用户空间页面，或者通过mmap（）建立的文件映射以及文件系统的读/写，具体的操作也不一样。这个写操作可能是同步的，也有可能是异步的，但总是需要一定的时间才能完成，在此期间内核有可能再次进入page_launcher(),所以需要放置这个页面再写一次。这就是把页面的PG_dirty标记位清成0的目的。这样，就不会把同一个页面写出两次了。此外，还要考虑页面写出失败的可能，具体的函数在写出失败时应该返回1，使page_launcher()可以恢复页面的PG_dirty标记位并将其退还给活跃页面队列中。

（4）如果页面不在是“脏”的，并且又是用作文件读/写缓冲的页面，则先使它多里不活跃“脏”页面队列，在通过try_to_free_buffers()试图将页面释放。如果不能释放则根据返回值将其退回不活跃“脏”页面队列，或者链入活跃页面队列，或者不活跃“干净”页面队列。如果释放成功，则页面的使用计数已经在try_to_free_buffers中减1，page_cache_release再使其减1就达到了0，从而将页面释放回到空闲页面队列中。如果成功地释放一个页面，并已发现系统中的空闲页面已经不再短缺，那么扫描可以结束了。否则继续扫描。

（5）如果页面不再是“脏”的，并且在某个address_space数据结构的队列中，这就是已经“清洗”了的页面，所以把它转移到所属区间的不活跃“干净”页面队列中。

（6）最后，如果不属于上诉的任何一种情况，那就无法处理的页面，所以把它退回活跃页面队列中。








