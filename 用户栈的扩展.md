# Memory-Management

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170405i.jpg "空间分布")

假设在进程运行的过程中，已经用尽了为本进程分配的堆栈区间，也就是从堆栈的“顶部”开始，已经到达了已映射的堆栈区间的下沿。或者说，CPU中的堆栈指针%esp已经指向堆栈区间的起始地址，如上图。

假定现在需要调用某个子程序，因此CPU需将返回地址压入堆栈，也就是要将返回地址写入虚存空间中地址为(%esp-4)的地方。可是，在我们这个情景中地址(%esp-4)落入了空洞中，这是尚未映射的地址，因此必然要引起一次页面错异常。

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170405j.jpg "空间分布")

这一次，空间上方的区间是堆栈区间，其VM_GROWSDOWN标志为1，所以CPU就继续往前执行。当映射失败发生在用户空间(bit2为1)时，因堆栈操作而引起的越界是作为特殊情况对待的，所以还需要检查发生异常时的地址是否紧挨着堆栈指针所指向的地方。在我们情景中，那个%esp-4,当然是紧挨着。但是如果是%esp-40呢，那就不会是因为正常的堆栈操作而引起，而是货真价实的非法越界访问了。可是，怎么来判定“正常”或“不正常”呢，通常，一次压入堆栈是4个字节，所以地址应该是%esp-4。但是i386CPU有一条pusha指令，可以一次将32字节压入堆栈。所以，检查的准则是%esp-32。超出这个范围就一定是错的了。在现在这个情景中，这个测试应是顺利通过的。

既然是属于正常的堆栈扩展要求，那就应该从空洞的顶部开始分配若干页面建立映射，并将之并入堆栈区，使其得以扩展。所以就要求调用expand_stack（）:

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170405k.jpg "空间分布")

参数vma指向一个vm_area_struct数据结构，代表着一个区间，在这里就是代表用户空间堆栈所在的区间。首先，将地址按页面边界对齐，并计算需要增长几个页面才能吧给定的地址包括进去。这里还有个问题，堆栈的这种扩展是否不受限制，直到把空间中的整个空洞用完为止呢？不是的，每个进程的个task_struct结构中都有rlim结构数组，规定了对每种资源分配使用的限制，而RLIMIT_STACK就是对用户空间堆栈大小的限制。所以，这里就进行这样的检查。如果扩展以后的区间大小超过了可用于堆栈的资源，或者使用动态分配的页面总量超过了可用于改进程的资源限制，那就不能扩展了，就会返回一个负的出错代码-ENOMEM，表示没有存储空间可以分配了；否则就应该返回0。当expand_stack（）返回值为非0，也即-ENOMEM时，在do_page_fault（）中也会转向bad_area。不过一般情况下都不至于用尽资源，所以expand_stack（）一般都是正常返回的。但是，我们已经看过，expand_stack()只是改变了堆栈区的vm_area_struct结构，而并未建立起新扩展的页面对物理内存的映射，这个任务由接下去的good_area完成。

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170406a.jpg "空间分布")

这里的switch语句中，内核根据由中断响应机制传过来的error_code来进一步确定映射失败原因并采取相应的策略(error_code最低三位的定义前面已给出)。就现在这个情景而言，bit0为0，便是没有物理页，而bit1为1表示写操作。所以，最低两位值为2。既然是写操作，当然要检查相应区间是否允许写入，而堆栈段是允许写入的。于是，就到达196行，调用虚存管理handle_mm_fault（）：

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170406b.jpg "空间分布")

根据给定的地址和代表着具体虚存空间的mm_struct数据结构，由宏操作pgd_offset（）计算出指向改地址所述页面目录项的指针。
```c
    #define pgd_index(address) ((address >> PGDIR_SHIFT) & (PTRS_PER_PGD1))
    #define PGDIR_SHIFT 22
    #define PTRS_PER_PGD 1024
    #define pgd_offset(mm, address) ((mm)->pgd+pgd_index(address))
```

页面目录总是在的，相应的目录项也许已经指向一个页面表，此时需要根据给定的地址在表中找到相应的页面表项。或则，目录项也可能还是空的，那样的话就需要先分配一个页面表，再在页面表中找到相应的表项。这样，才可以为下面分配物理内存页面建立映射好的准备。这是通过pte_alloc()完成的。

```c
 extern inline pte_t * pte_alloc(pmd_t * pmd, unsigned long address)
 {
       address = (address >> PAGE_SHIFT) & (PTRS_PER_PTE 1);
       if (pmd_none(*pmd))
             goto getnew;
       if (pmd_bad(*pmd))
             goto fix;
       return (pte_t *)pmd_page(*pmd) + address;
getnew:
{ 
      unsigned long page = (unsigned long) get_pte_fast();
      if (!page)
            return get_pte_slow(pmd, address);
      set_pmd(pmd, __pmd(_PAGE_TABLE + __pa(page)));
      return (pte_t *)page + address;
}
fix:
      __handle_bad_pmd(pmd);
      return NULL;
}
```

分配到一个页面表以后，就通过set_pmd()将其起始地址连同一些属性标记位一起写入中间目录项pmd中，而对i386却实际上上写入到页面目录项pgd中。这样，映射所需的“基础设施”都已经齐全了，但页面表项pte还是空的。剩下来的就是物理内存页面本身了，那是由handle_pte_fault（）完成的。

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170406c.jpg "空间分布")

在我们这个情景里，不管页面表是新分配的还是原先就有的，相应的页面表项却一定是空的。这样，程序一开头的if语句的条件一定能满足，因为pte_present测试一个表项锁映射的页面是否在内存中，而夜里内存页面还没有分配。进一步，pte_none（）所测试的条件一定能满足，因为他测试一个表项是否为空。所以，就必定会进入do_no_page（）（或者就是do_swap_page（））。顺便讲一下，如果pte_present的测试结果是该表项所映射的页面确实在内存中，那么问题一定出现在访问权限，或者根本没有问题。

```c
 static int do_no_page(struct mm_struct * mm, struct vm_area_struct * vma,
 unsigned long address, int write_access, pte_t *page_table)
 {
    struct page * new_page;
    pte_t entry;
    
if (!vma->vm_ops || !vma->vm_ops->nopage)
    return do_anonymous_page(mm, vma, page_table, write_access, address);
    ......
```
在虚存区间结构vm_area_struct中有个指针vm_ops,指向vm_operations_struct数据结构。这个数据结构实际上是个函数跳转表，结构中通常是一些与文件操作有关的函数指针。其中有一个函数指针就是用于物理内存页面的分配。物理内存页面的分配为什么与文件操作有关呢？因为针对于可能文件共享很有意义。当多个进程将同一个文件映射到各自的虚存空间中时，内存中通常只保留一份物理页面就可以了。只有当一个进程需要写入该文件时才有必要另外复制一个独立的副本。这样，当通过mmap()将一块虚存区间跟一个已打开文件建立映射后，就可以通过对这些函数的调用将内存的操作转化为对文件的操作，或者进行一些必要的对文件的附加操作。另一方面，物理页面的盘区交换显然也是跟文件操作有关的。所以，为特定的虚存空间预先指定一些特定的操作是很有必要的。于是，如果已经预先为一个虚存区间vma指定了分配物理内存页面的操作的话，那就是vma->vm_ops->nopage（）。但是，vma->vm_ops和vm->vm_ops->nopage都有可能是空，那就表示没有为止指定具体的nopage(）操作，或者根本没有配备一个vm_operations_struct结构。当没有指定的nopage()操作时，内核就调用一个函数do_anonymous_page（）来分配物理内存页面。

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170407a.jpg "空间分布")

首先注意到，如果引起页面异常的是一次读操作，那么由mk_pte（）构筑的映射表项通过pte_wrprotect加以修正；而如果是写操作(参数write_access为非0)，则通过pte_mkwrite()加以修正。两者的不同如下：

```c
   static inline pte_t pte_wrprotect(pte_t pte) { (pte).pte_low &= ~_PAGE_RW; return pte; }
   static inline int pte_write(pte_t pte) { return (pte).pte_low & _PAGE_RW; }
```

对比一下，就可看出，在pte_wrprotect()中,把PAGE_RW标志设成0，表示这个物理页面只允许读；而在pte_write()却把这个表示设成1。同时，对于读操作，所映射的物理页面总是ZERO_PAGE。
```c
    #define ZERO_PAGE(vaddr) (virt_to_page(empty_zero_page))
```
就是说，只要是“只读”的页面，开始都一律映射到同一个物理内存页面empty_zero_page,而不管其虚拟地址是什么。实际上，这个页面的内容为全0，所以映射之初若从该页面读出就读得0.只有可写的页面，才通过alloc_page()为其分配独立的物理内存。在我们这个情景里，所需要的页面是在堆栈区，并且是由于写操作才引起异常的，所以要通过alloc_page()为其分配一个物理内存页面，并将分配到物理页面两桶所有的状态及标志位，一起通过set_pte（）设置进指针page_table所指的页面表项。至此，从虚存页面到物理内存页面的映射终于建立完了。

最后，特别要指出，当CPU从一次页面所异常处理返回到用户空间时，将会先重新执行因映射失败而中途夭折的那条指令，然后才继续往下执行，这是异常处理的特殊性。学过有关课程的都知道，中断以及自险(trap指令)发生时，CPU都会将下一条指令，也就是接下去本来应该执行的指令的地址压入堆栈作为中断服务的返回地址。但是异常却不同。当异常发生时，CPU将因无法完成而夭折的指令本身的地址压入堆栈。这样就可以在从异常处理返回时完成未竟的事业。这个是由CPU内部电路实现，而非软件，从某种意义上说，这个应该叫“缺页异常”而非“缺页中断”。对用户程序来说，这整个过程都是“透明”的，就像什么事也没有发生，而在堆栈区间就像从一开始就分配了好了足够大的空间一样。
