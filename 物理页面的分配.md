# Memory Management

上一节中曾经提到，当需要分配若干内存页面时，用于DMA的内存页面必须是连续的。其实，为便于管理，特别是出于对物理存储空间"质地"一致性的考虑，即使不是用于DMA的内存页面也是连续分配的。

当一个进程需要分配若干连续的物理页面时，可以通过alloc_pages()来完成。Linux内核2.4.0版代码有两个alloc_pages(),一个在mm/numa.c中，另一个在mm/page_alloc.c中，编译时根据所定义的条件编译选择项CONFIG_DISCONTIGMEM决定取舍。为什么呢？这就是出于前一节中所述对物理存储空间“质地”一致性的考虑。

NUMA结构的alloc_pages():

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170413a.jpg)
![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170413b.jpg)

CONFIG_DISCONTIGMEM有定义时才得到编译。不过，这里用作为条件的是“不连续存储空间”，而不是CONFIG_NUMA。其实，不连续的物理存储空间是一种广义的NUMA，因为那说明在最低物理地址和最高物理地址之间存在着空洞，而有空洞的空间当然是非均质的。所以在地址不连续的物理空间也要像在质地不均匀的物理空间那样划分出连续（而且均匀）的“节点”。所以，在存储空间不连续的系统中，每个模块都有若干个节点，因而都有个pg_data_t数据结构的队列。调用时有两个参数。第一个参数gfp_mask是个整数，表示采用哪一种分配策略；第二个参数order表示所需的物理块的大小，可以是1,2,4，...，直到2的MAX_ORDER次幂个页面。

在NUMA结构的系统中，可以通过宏操作NUMA_DATA和numa_node_id（）找到CPU所在节点pg_data_t数据结构队列。而不在连续存储空间结构中，则也有个pg_data_t数据结构的队列pgdat_list,分配时轮流从各个节点开始，以求各个节点负荷的平衡。

函数中主要的操作在于两个while循环，他们分两截（先是从temp开始到队列的末尾，然后回头从第一个节点到最初开始的地方）扫描队列中所有节点，直至在某个节点内分配成功，或彻底失败而返回0,。对于每个节点，调用alloc_pages_pgdat（）试图分配所需的页面，这个函数的代码在mm/numa.c中：

```c++
static struct page * alloc_pages_pgdat(pg_data_t *pgdat, int gfp_mask,unsigned long order)
{
     return __alloc_pages(pgdat->node_zonelists + gfp_mask, order);
}
```

可见，参数gfp_mask在这里用作给定节点中数组node_zonelist[]的下标，决定具体的分配策略。把这段代码与下面用于连续UMA结构的alloc_pages（）对照一下，就可以看出区别：在连续空间UMA结构中只有一个节点contig_page_data，而在NUMA结构或不连续的UMA结构中则有多个。
连续空间的UMA结构的alloc_pages()是在文件include/linux/mm.h中定义的：

```C++
#ifndef CONFIG_DISCONTIGMEM
static inline struct page * alloc_pages(int gfp_mask, unsigned long order)
{
    /*
     * Gets optimized away by the compiler.
     */
    if (order >= MAX_ORDER)
         return NULL;
    return __alloc_pages(contig_page_data.node_zonelists+(gfp_mask), order);
}
```

与NUMA结构alloc_pages()相反，这个函数仅在CONFIG_DISCONTIGMEM无定义时才得到编译。所以这两个同名的函数只有一个会得到编译。

具体的页面分配有函数__alloc_pages()完成，其代码在mm/page_alloc.c中：

```c++
[alloc_pages()>__alloc_pages()]
     /*
      * This is the 'heart' of the zoned buddy allocator:
      */
     struct page * __alloc_pages(zonelist_t *zonelist, unsigned long order)
     {
          zone_t **zone;
          int direct_reclaim = 0;
          unsigned int gfp_mask = zonelist->gfp_mask;
          struct page * page;

    /*
     * Allocations put pressure on the VM subsystem.
     */
          memory_pressure++;

    /*
     * (If anyone calls gfp from interrupts nonatomically then it
     * will sooner or later tripped up by a schedule().)
     *
     * We are falling back to lower-level zones if allocation
     * in a higher zone fails.
     */

    /*
     * Can we take pages directly from the inactive_clean
     * list?
     */
          if (order == 0 && (gfp_mask & __GFP_WAIT) && !(current->flags & PF_MEMALLOC))
            direct_reclaim = 1;

     /*
      * If we are about to get low on free pages and we also have
      * an inactive page shortage, wake up kswapd.
      */
          if (inactive_shortage() > inactive_target / 2 && free_shortage())
             wakeup_kswapd(0);
      /*
       * If we are about to get low on free pages and cleaning
       * the inactive_dirty pages would fix the situation,
       * wake up bdflush.
       */
          else if (free_shortage() && nr_inactive_dirty_pages > free_shortage() && nr_inactive_dirty_pages >= freepages.high)
             wakeup_bdflush(0);
```

调用时有两个参数。第一个参数zonelist指向代表着一个具体分配策略的zonelist_t数据结构。另外一个参数order则与前面alloc_pages（）中的相同。全局量memory_pressure表示内存管理所受的压力，分配内存页面时递增，归还时则递减。这里的局部量gfp_mask来自代表着具体分配策略的数据结构，是一些用于控制目的标记位。如果要求分配的只是单个页面，而且要等待分配完成，又不是用于管理目的，则把一个局部量direct_reclaim设成1，表示可以从相应页面管理区的“不活跃干净页面”缓冲队列中回收。这些页面的内容都已写入至页面交换设备或文件中，只是当空闲页面短缺时，就顾不得那么多了。由于一般而言这些页面不一定像真正的空闲页面那样连成块，所以仅在要求分配单个页面时才能从这些页面中回收。此外，当发现可分配页面短缺时，还有唤醒kswapd和bdflush两个内核线程，让它们设法腾出一些内存页面来。

```c++
[alloc_pages()>__alloc_pages()]
try_again:
    /*
     * First, see if we have any zones with lots of free memory.
     *
     * We allocate free memory first because it doesn't contain
     * any data ... DUH!
     */
     zone = zonelist->zones;
     for (;;) {
         zone_t *z = *(zone++);
         if (!z)
             break;
         if (!z->size)
             BUG();

         if (z->free_pages >= z->pages_low) {
            page = rmqueue(z, order);
            if (page)
                return page;
         } else if (z->free_pages < z->pages_min && waitqueue_active(&kreclaimd_wait)) {
            wake_up_interruptible(&kreclaimd_wait);
         }
     }
```
这是对一个分配策略中所规定的所有页面管理区的循环。循环中一次考察各个管理区中空闲页面的总量，如果总量尚在“低水位”以上，就通过rmqueue()试图从该管理区中分配。要是发现管理区中的空闲页面总量已经降到了最低点，而且有进程（实际上只能是内核线程kreclaimd）在一个等待队列kreclaimd_wait中睡眠，就把它唤醒，让它帮助回收一些页面备用。函数rmqueue（）试图从一个页面管理区分配若干连续的页面，其代码在mm/page_alloc.c中：

```c++
[alloc_pages()>__alloc_pages()>rmqueue()]
static struct page * rmqueue(zone_t *zone, unsigned long order)
{
    free_area_t * area = zone->free_area + order;
    unsigned long curr_order = order;
    struct list_head *head, *curr;
    unsigned long flags;
    struct page *page;

    spin_lock_irqsave(&zone->lock, flags);
    do {
        head = &area->free_list;
        curr = memlist_next(head);
        if (curr != head) {
            unsigned int index;
            page = memlist_entry(curr, struct page, list);
            if (BAD_RANGE(zone,page))
                BUG();
            memlist_del(curr);
            index = (page - mem_map) - zone->offset;
            MARK_USED(index, curr_order, area);
            zone->free_pages -= 1 << order;

            page = expand(zone, page, index, order, curr_order, area);
            spin_unlock_irqrestore(&zone->lock, flags);

            set_page_count(page, 1);
            if (BAD_RANGE(zone,page))
               BUG();
          DEBUG_ADD_PAGE
          return page;
     }
     curr_order++;
     area++;
     } while (curr_order < MAX_ORDER);
     spin_unlock_irqrestore(&zone->lock, flags);
     return NULL;
}
```
