# Memory Management

上一节中曾经提到，当需要分配若干内存页面时，用于DMA的内存页面必须是连续的。其实，为便于管理，特别是出于对物理存储空间"质地"一致性的考虑，即使不是用于DMA的内存页面也是连续分配的。

当一个进程需要分配若干连续的物理页面时，可以通过alloc_pages()来完成。Linux内核2.4.0版代码有两个alloc_pages(),一个在mm/numa.c中，另一个在mm/page_alloc.c中，编译时根据所定义的条件编译选择项CONFIG_DISCONTIGMEM决定取舍。为什么呢？这就是出于前一节中所述对物理存储空间“质地”一致性的考虑。

NUMA结构的alloc_pages():

![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170413a.jpg)
![image](https://github.com/wangdongyu1989/Memory-Management/blob/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%8420170413b.jpg)

CONFIG_DISCONTIGMEM有定义时才得到编译。不过，这里用作为条件的是“不连续存储空间”，而不是CONFIG_NUMA。其实，不连续的物理存储空间是一种广义的NUMA，因为那说明在最低物理地址和最高物理地址之间存在着空洞，而有空洞的空间当然是非均质的。所以在地址不连续的物理空间也要像在质地不均匀的物理空间那样划分出连续（而且均匀）的“节点”。所以，在存储空间不连续的系统中，每个模块都有若干个节点，因而都有个pg_data_t数据结构的队列。调用时有两个参数。第一个参数gfp_mask是个整数，表示采用哪一种分配策略；第二个参数order表示所需的物理块的大小，可以是1,2,4，...，直到2的MAX_ORDER次幂个页面。

在NUMA结构的系统中，可以通过宏操作NUMA_DATA和numa_node_id（）找到CPU所在节点pg_data_t数据结构队列。而不在连续存储空间结构中，则也有个pg_data_t数据结构的队列pgdat_list,分配时轮流从各个节点开始，以求各个节点负荷的平衡。

函数中主要的操作在于两个while循环，他们分两截（先是从temp开始到队列的末尾，然后回头从第一个节点到最初开始的地方）扫描队列中所有节点，直至在某个节点内分配成功，或彻底失败而返回0,。对于每个节点，调用alloc_pages_pgdat（）试图分配所需的页面，这个函数的代码在mm/numa.c中：

```c++
static struct page * alloc_pages_pgdat(pg_data_t *pgdat, int gfp_mask,unsigned long order)
{
     return __alloc_pages(pgdat->node_zonelists + gfp_mask, order);
}
```

可见，参数gfp_mask在这里用作给定节点中数组node_zonelist[]的下标，决定具体的分配策略。把这段代码与下面用于连续UMA结构的alloc_pages（）对照一下，就可以看出区别：在连续空间UMA结构中只有一个节点contig_page_data，而在NUMA结构或不连续的UMA结构中则有多个。
连续空间的UMA结构的alloc_pages()是在文件include/linux/mm.h中定义的：

```C++
#ifndef CONFIG_DISCONTIGMEM
static inline struct page * alloc_pages(int gfp_mask, unsigned long order)
{
    /*
     * Gets optimized away by the compiler.
     */
    if (order >= MAX_ORDER)
         return NULL;
    return __alloc_pages(contig_page_data.node_zonelists+(gfp_mask), order);
}
```

与NUMA结构alloc_pages()相反，这个函数仅在CONFIG_DISCONTIGMEM无定义时才得到编译。所以这两个同名的函数只有一个会得到编译。

具体的页面分配有函数_alloc_pages()完成，其代码
